{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT: TEXT CLASSIFICATION\n",
    "## Part 1 - Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"data/movie_plots_tc.csv\", encoding=\"utf-8\",errors=\"ignore\") as csv_file :\n",
    "    df = pd.read_csv(csv_file, sep=\";\")\n",
    "plots = df[\"Plot\"]\n",
    "labels = df[\"Genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "str2id={'western':0,'drama':1,'comedy':2}\n",
    "id2str={0:'western',1:'drama',2:'comedy'}\n",
    "\n",
    "list_plots=plots.fillna(\"CVxTz\").values\n",
    "indexed_labels=np.array([str2id[l] for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(list_plots, indexed_labels, test_size=0.25 , random_state=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.file_utils import is_tf_available, is_torch_available\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "max_lenght = 256\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_features.tolist(),truncation=True, padding=True, max_length=max_lenght)\n",
    "val_encodings = tokenizer(val_features.tolist(),truncation=True, padding=True, max_length=max_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurTorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OurTorchDataset(train_encodings, train_labels)\n",
    "val_dataset = OurTorchDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINETUNING TEXT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name,num_labels=3).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/Model\",\n",
    "    num_train_epochs= 3 ,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    seed=1895,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset= train_dataset,\n",
    "    eval_dataset= val_dataset,\n",
    "    compute_metrics= compute_metrics,\n",
    "    \n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:08<00:00, 39.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9536789655685425,\n",
       " 'eval_accuracy': 0.7987152034261242,\n",
       " 'eval_runtime': 8.9502,\n",
       " 'eval_samples_per_second': 313.065,\n",
       " 'eval_steps_per_second': 39.217,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    #Prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation = True, max_length = max_lenght, return_tensors = \"pt\").to(\"cuda\")\n",
    "    # perfom inference to our model \n",
    "    outputs = model(**inputs )\n",
    "    # get out probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return id2str[probs.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drama'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"The duo decide to search for the gold together, but they are apprehended by Union forces shortly after leaving the mission - Tuco yells out Confederate-supportive statements at a group of Union soldiers, as they are covered in dust, obscuring the blue color of their uniforms. The two are brought to a prison camp which Angel infiltrated as a Union sergeant in his search for Bill Carson, getting his attention when Tuco poses as Bill Carson. Tuco reveals the name of the cemetery under torture and is sent away to be killed. Knowing that Blondie would not reveal the location, Angel Eyes recruits him into his search. Tuco escapes his fate by killing Angel Eyes' henchman, and soon finds himself in an evacuated town, where Blondie, Angel Eyes, and his gang have also arrived. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'western'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film =\"In the heart of the American frontier, 'The Unforgiving Plains' unfolds as a gripping tale of revenge and redemption. Set against the vast, unforgiving landscape of the Wild West in the late 1800s, the story follows the journey of Jacob Calloway, a stoic former gunslinger who has turned his back on violence to live a peaceful life on his homestead. However, when a ruthless gang terrorizes his town and threatens his family, Jacob is compelled to pick up his guns once more and confront the demons of his past. Directed with a keen eye for tension and dramatic landscapes, the film is a masterclass in storytelling, weaving together themes of loyalty, justice, and the unbreakable human spirit. With stunning cinematography that captures the brutal beauty of the frontier and performances that bring depth and nuance to the archetypal characters, 'The Unforgiving Plains' is a modern Western classic that pays homage to the genre while charting its own unique path.\"\n",
    "get_prediction(film)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
